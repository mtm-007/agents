{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc7dd25-c0c5-4529-a500-db3e87975b50",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef82a35-8d5c-44fd-8be2-fbd2660bfb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb95e953-63a2-421f-b4a6-9a9a946da18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e7a2a8-40da-4700-b535-86e6149a0d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x77105e343710>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minsearch import AppendableIndex\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields = [\"question\", \"text\", \"section\"],\n",
    "    keyword_fields = [\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b25824b-16a5-42fd-a509-c902cafc898c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'While following tutorial 13.2 , when running ./spark-submit.sh streaming.py, encountered the following error:\\n…\\n24/03/11 09:48:36 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://localhost:7077...\\n24/03/11 09:48:36 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:7077 after 10 ms (0 ms spent in bootstraps)\\n24/03/11 09:48:54 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\\n24/03/11 09:48:56 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://localhost:7077…\\n24/03/11 09:49:16 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://localhost:7077...\\n24/03/11 09:49:36 WARN StandaloneSchedulerBackend: Application ID is not initialized yet.\\n24/03/11 09:49:36 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.\\n…\\npy4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.sql.SparkSession.\\n: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\\n…\\nSolution:\\nDowngrade your local PySpark to 3.3.1 (same as Dockerfile)\\nThe reason for the failed connection in my case was the mismatch of PySpark versions. You can see that from the logs of spark-master in the docker container.\\nSolution 2:\\nCheck what Spark version your local machine has\\npyspark –version\\nspark-submit –version\\nAdd your version to SPARK_VERSION in build.sh',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Python Kafka: ./spark-submit.sh streaming.py - ERROR StandaloneSchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Start a new terminal\\nRun: docker ps\\nCopy the CONTAINER ID of the spark-master container\\nRun: docker exec -it <spark_master_container_id> bash\\nRun: cat logs/spark-master.out\\nCheck for the log when the error happened\\nGoogle the error message from there',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Python Kafka: ./spark-submit.sh streaming.py - How to check why Spark master connection fails',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\nKafka Python Videos - Rides.csv\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Kafka- python videos have low audio and hard to follow up',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'For example, when running JsonConsumer.java, got:\\nConsuming form kafka started\\nRESULTS:::0\\nRESULTS:::0\\nRESULTS:::0\\nOr when running JsonProducer.java, got:\\nException in thread \"main\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\nSolution:\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\nfastavro: pip install fastavro\\nAbhirup Ghosh\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\nSolution:\\nIn build.gradle file, I added the following at the end:\\nshadowJar {\\narchiveBaseName = \"java-kafka-rides\"\\narchiveClassifier = \\'\\'\\n}\\nAnd then in the command line ran ‘gradle shadowjar’, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Run this command in terminal in the same directory (/docker/spark):\\nchmod +x build.sh',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Python Kafka: ./build.sh: Permission denied Error',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'If you get this error, know that you have not built your sparks and juypter images. This images aren’t readily available on dockerHub.\\nIn the spark folder, run ./build.sh from a bash cli to to build all images before running docker compose',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': \"How to fix docker compose error: Error response from daemon: pull access denied for spark-3.3.1, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\",\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'You can check the version of your local spark using spark-submit --version. In the build.sh file of the Python folder, make sure that SPARK_VERSION matches your local version. Similarly, make sure the pyspark you pip installed also matches this version.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'How do I check compatibility of local and container Spark versions?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(\"how to use kafka with spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd2d7d5c-f703-48e7-8083-9fd9250f849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33cd3a60-1729-4dcc-beb5-fd311cdf0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"how to use kafka with spark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a8fc61d-d08b-456f-ad1d-6d6a42b1642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9ee9f5c-d9e4-4638-9eca-5c9207a033a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "107bfa23-cda8-4ef3-bc0d-07a2efee876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(question, search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdd9be5a-2d6b-431f-a282-bb6485a93f14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "<QUESTION>\n",
      "how do I do well in module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT>\n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "\n",
      "</CONTEXT>\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c1bc124-3bb6-4ba2-a06f-7ce208cb4aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90deb85e-d269-47dd-93b7-a4f51c83f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8a0d682-3437-4dd5-8ba9-e6fc99b70e4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To do well in Module 1, focus on the following points:\n",
      "\n",
      "1. **Ensure All Modules Are Installed**: Make sure you have all the required modules installed. Specifically, if you encounter a `ModuleNotFoundError` related to `psycopg2`, you will need to install it using either Conda or pip.\n",
      "\n",
      "2. **Use the Correct Connection String**: When working with SQLAlchemy, be aware of the connection string format. Instead of using `create_engine('postgresql://root:root@localhost:5432/ny_taxi')`, use `conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"` and then create the engine.\n",
      "\n",
      "By following these steps, you can effectively navigate the challenges presented in Module 1.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ada1dbd2-8ada-4dcc-b5f6-0b66bcacc893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To use Kafka with Spark, you can follow these general steps:\\n\\n1. **Set Up Kafka and Spark**: Ensure that you have Kafka and Spark running, typically in Docker containers. You can confirm their status using `docker ps` to see if the necessary containers are operational.\\n\\n2. **Check Kafka Broker**: If you encounter the error `kafka.errors.NoBrokersAvailable`, it indicates that your Kafka broker might not be working. You can start the broker by navigating to the folder containing your `docker-compose.yaml` file and running `docker compose up -d`.\\n\\n3. **Submit Spark Job**: Use the command `./spark-submit.sh streaming.py` to run your Spark job. Ensure that the versions of PySpark on your local machine and any Docker images being used are compatible to avoid connection issues (e.g., if there are errors about the Spark master being unresponsive, it may be caused by version mismatches).\\n\\n4. **Log Checking**: If you encounter issues with Spark master connection, open a new terminal and check the logs of the Spark master container for any error messages, which can be done with the commands:\\n   - `docker exec -it <spark_master_container_id> bash`\\n   - `cat logs/spark-master.out`\\n\\n5. **Monitor Errors**: Look for specific error messages in the logs and search for solutions, as these can guide you on what adjustments or fixes might be needed next.\\n\\nBy following these steps, you should be able to establish a functioning connection between Kafka and Spark in your streaming application.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e88740-b4f1-45e1-87da-f3308733796d",
   "metadata": {},
   "source": [
    "#### 'Agentic' RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc9a26bf-f640-42ce-a773-8c3273fac948",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a course teaching assistant.\n",
    "\n",
    "You are given a Question from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "At the beginning the context is EMPTY.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "If CONTEXT is EMPTY, you can use your FAQ database.\n",
    "In this case, use the following output template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\"\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\" : \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\" : \"ANSWER\",\n",
    "\"answer\" : \"<your answer>\",\n",
    "\"source\" : \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a7bd20e-0f69-4260-9c00-7b1ad9551622",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Can i still join the course?\"\n",
    "context = \"EMPTY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1903578f-e1f7-4e95-87c2-86d0fbe79950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a course teaching assistant.\n",
      "\n",
      "You are given a Question from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "Can i still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT>\n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use your FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\" : \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\" : \"ANSWER\",\n",
      "\"answer\" : \"<your answer>\",\n",
      "\"source\" : \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d378fa25-e1a6-4ec3-85c2-acf7fddc04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec652cb6-1566-4b1b-a7de-1fd991f1e495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dbf2409-3072-45f2-a166-b6de5f76d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = json.loads(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ec3c12c-84fb-47ff-923d-9b424e8fb5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEARCH'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[\"action\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a44cc728-d30a-4414-acc2-1e2c0792c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d4d4898-156d-44ec-96b3-ec7ba80db9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search(question)\n",
    "context = build_context(search_results)\n",
    "prompt = prompt_template.format(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e043985e-8559-46d9-9773-ce52af3dd340",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a809f869-c075-446a-8812-2731e28a7ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"Yes, you can still join the course after the start date, even if you haven't officially registered. You are eligible to submit homework assignments, but keep in mind that there will be deadlines for the final projects that you should not overlook.\",\n",
      "\"source\" : \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1033a310-c67f-4597-93b8-613c854bb52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_rag_v1(question):\n",
    "    context = \"EMPTY\"\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(answer)\n",
    "\n",
    "    if answer[\"action\"]==\"SEARCH\":\n",
    "        print(\"need to perform search...\")\n",
    "        search_results = search(question)\n",
    "        context = build_context(search_results)\n",
    "\n",
    "        prompt = prompt_template.format(question=question, context=context)\n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ab1e3a6-af05-40ac-9829-10dbde2f81e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'ANSWER', 'answer': \"To join the course, you typically need to enroll through the course website or platform where it is hosted. Look for a button or link that says 'Enroll Now' or 'Join the Course'. You may also need to create an account if you haven't already. If there are prerequisites or specific requirements, make sure to complete those as well.\", 'source': 'OWN_KNOWLEDGE'}\n",
      "CPU times: user 3.46 ms, sys: 953 μs, total: 4.42 ms\n",
      "Wall time: 2.27 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To join the course, you typically need to enroll through the course website or platform where it is hosted. Look for a button or link that says 'Enroll Now' or 'Join the Course'. You may also need to create an account if you haven't already. If there are prerequisites or specific requirements, make sure to complete those as well.\",\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "agentic_rag_v1(\"how do i join the course?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f56dd4-6975-4d46-b13e-e7338e3d21eb",
   "metadata": {},
   "source": [
    "#### Agentic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c500652d-62e4-4f8f-81ac-259043dbc3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedub(seq):\n",
    "    \"\"\"\n",
    "    deduplicates by skipping the repeating element('_id')\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for el in seq:\n",
    "        _id = el['_id']\n",
    "        if _id in seen:\n",
    "            continue\n",
    "        seen.add(_id)\n",
    "        result.append(el)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a8b0793-d42b-4e0d-9c4e-843aedc00558",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a course teaching assistant.\n",
    "\n",
    "You are given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "\n",
    "The CONTEXT is build with the documents from our FAQ database.\n",
    "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
    "from FAQ to and add them to the context.\n",
    "PREVIOUS_ACTIONS contains the actions you already performed.\n",
    "\n",
    "At the beginning the CONTEXT is empty.\n",
    "\n",
    "You can perform the following actions:\n",
    "\n",
    "- Search in the FAQ database to get more data for the CONTEXT\n",
    "- Answer the question using the CONTEXT\n",
    "- Answer the question using your own knowledge\n",
    "\n",
    "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
    "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
    "\n",
    "Don't use search queries used at the previous iterations.\n",
    "\n",
    "Don't repeat previously performed actions.\n",
    "\n",
    "Don't perform more than {max_iterations} iterations for a given student question.\n",
    "The current iteration number: {iteration_number}. If we exceed the allowed number\n",
    "of iterations, give the best possible answer with the provided information.\n",
    "\n",
    "Output templates:\n",
    "\n",
    "If you want to perform search, use this template:\n",
    "\n",
    "{{\n",
    "\"action\" : \"SEARCH\",\n",
    "\"reasoning\" : \"<add your reasoning here>\",\n",
    "\"keywords\" : [\"search query 1\", \"search query 2\", ...]\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\" : \"ANSWER_CONTEXT\",\n",
    "\"answer\" : \"<your answer>\",\n",
    "\"source\" :\"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\" : \"ANSWER\",\n",
    "\"answer\" : \"<your answer>\",\n",
    "\"source\" : \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<SEARCH_QUERIES>\n",
    "{search_queries}\n",
    "</SEARCH_QUERIES>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "<PREVIOUS_ACTIONS>\n",
    "{previous_actions}\n",
    "</PREVIOUS_ACTIONS>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a52001d-e882-42ad-8c8a-1bed7e435b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"how do I do well on module 1\"\n",
    "\n",
    "max_iterations = 3\n",
    "iteration_number = 0\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d55f6e25-5d48-453e-a2ad-8daed7a07c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question = question,\n",
    "    context = context,\n",
    "    search_queries = \"\\n\".join(search_queries),\n",
    "    previous_actions = \"\\n\".join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "324e17b1-72d8-4d65-9424-9a6c80f4acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7542a4d2-2702-4a48-b494-2a38997a1490",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = json.loads(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6d7af6f-8e7a-489c-a5bd-54d3d86669c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'SEARCH',\n",
       " 'reasoning': 'I need to gather more specific insights and advice on succeeding in Module 1, especially since the previous search did not yield any relevant results related to strategies for success in the module.',\n",
       " 'keywords': ['succeeding in Module 1',\n",
       "  'Module 1 study tips',\n",
       "  'best practices for Module 1']}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48b0257d-e366-428c-98f9-e67f3abea160",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_actions.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c012b71-037b-4663-8788-39546624eb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'action': 'SEARCH',\n",
       "  'reasoning': 'I want to find specific tips and resources related to success strategies for module 1 to better inform the student.',\n",
       "  'keywords': ['how to succeed in module 1',\n",
       "   'tips for module 1',\n",
       "   'module 1 best practices']},\n",
       " {'action': 'SEARCH',\n",
       "  'reasoning': 'I need to gather more specific insights and advice on succeeding in Module 1, especially since the previous search did not yield any relevant results related to strategies for success in the module.',\n",
       "  'keywords': ['succeeding in Module 1',\n",
       "   'Module 1 study tips',\n",
       "   'best practices for Module 1']}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95ff6a22-10bb-46e8-8ec4-e50021eb04e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = answer['keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2a52d8a7-7e4f-4169-af75-984f6341ec34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['succeeding in Module 1', 'Module 1 study tips', 'best practices for Module 1']\n"
     ]
    }
   ],
   "source": [
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c4ddbe5-e3c0-4a45-8c52-3f53472cff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kw in keywords:\n",
    "    search_queries.append(kw)\n",
    "    sr = search(kw)\n",
    "    search_results.extend(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "437f178a-21fd-4974-875b-eeebe47d1f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = dedub(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "062d4761-c4ae-4659-8622-537b4751a9c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc4d319-c0c7-4688-9571-1a52ce84203d",
   "metadata": {},
   "source": [
    "##### Running iterations manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c032302d-da5c-4b0f-b2e5-2aa8f5f4faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_number = 3\n",
    "\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question = question,\n",
    "    context = context,\n",
    "    search_queries = \"\\n\".join(search_queries),\n",
    "    previous_actions = \"\\n\".join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f5da2459-6d51-4518-9582-094a215e3598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a course teaching assistant.\n",
      "\n",
      "You are given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 3. If we exceed the allowed number\n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\" : \"SEARCH\",\n",
      "\"reasoning\" : \"<add your reasoning here>\",\n",
      "\"keywords\" : [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\" : \"ANSWER_CONTEXT\",\n",
      "\"answer\" : \"<your answer>\",\n",
      "\"source\" :\"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\" : \"ANSWER\",\n",
      "\"answer\" : \"<your answer>\",\n",
      "\"source\" : \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I do well on module 1\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to succeed in module 1\n",
      "tips for module 1\n",
      "module 1 best practices\n",
      "succeeding in Module 1\n",
      "Module 1 study tips\n",
      "best practices for Module 1\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT>\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker - cs to store all code in your default Linux distro to get the best out of file system performance (since Docker runs on WSL2 backend by default for Windows 10 Home / Windows 11 Home users).\n",
      "answer: More info in the Docker Docs on Best Practises\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"I want to find specific tips and resources related to success strategies for module 1 to better inform the student.\", \"keywords\": [\"how to succeed in module 1\", \"tips for module 1\", \"module 1 best practices\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"I need to gather more specific insights and advice on succeeding in Module 1, especially since the previous search did not yield any relevant results related to strategies for success in the module.\", \"keywords\": [\"succeeding in Module 1\", \"Module 1 study tips\", \"best practices for Module 1\"]}\n",
      "</PREVIOUS_ACTIONS>\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68f347d2-2e0a-4416-b368-3fb4cda40c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4ddf7ced-88d1-4890-b5a6-5869d566d0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"To do well in Module 1, which focuses on Docker and Terraform, consider the following strategies:\\n\\n1. **Understand the Basics:** Make sure you have a solid understanding of Docker concepts such as containers, images, and orchestration. Familiarize yourself with Terraform's infrastructure as code approach and its basic commands.\\n\\n2. **Hands-On Practice:** Engage in practical exercises by setting up your own Docker containers and using Terraform to manage infrastructure. The more you practice, the better you'll grasp these tools.\\n\\n3. **Utilize Resources:** Leverage the course materials, documentation, and online tutorials to reinforce your learning. Community forums can also provide assistance if you encounter challenges.\\n\\n4. **Manage Dependencies:** Be aware of common issues such as 'ModuleNotFoundError' for libraries like Psycopg2 or other dependencies. Make sure to install and update them as needed.\\n\\n5. **Collaborate:** If possible, work with peers to share insights and tackle challenges together. Collaboration can deepen your understanding of difficult concepts.\\n\\nBy following these tips, you should be able to navigate Module 1 successfully and build a strong foundation for future modules.\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "287ebd52-aed7-4fc8-b444-e2d64f3616b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = json.loads(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "71818a41-5295-46eb-8e8b-539911729bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To do well in Module 1, which focuses on Docker and Terraform, consider the following strategies:\n",
      "\n",
      "1. **Understand the Basics:** Make sure you have a solid understanding of Docker concepts such as containers, images, and orchestration. Familiarize yourself with Terraform's infrastructure as code approach and its basic commands.\n",
      "\n",
      "2. **Hands-On Practice:** Engage in practical exercises by setting up your own Docker containers and using Terraform to manage infrastructure. The more you practice, the better you'll grasp these tools.\n",
      "\n",
      "3. **Utilize Resources:** Leverage the course materials, documentation, and online tutorials to reinforce your learning. Community forums can also provide assistance if you encounter challenges.\n",
      "\n",
      "4. **Manage Dependencies:** Be aware of common issues such as 'ModuleNotFoundError' for libraries like Psycopg2 or other dependencies. Make sure to install and update them as needed.\n",
      "\n",
      "5. **Collaborate:** If possible, work with peers to share insights and tackle challenges together. Collaboration can deepen your understanding of difficult concepts.\n",
      "\n",
      "By following these tips, you should be able to navigate Module 1 successfully and build a strong foundation for future modules.\n"
     ]
    }
   ],
   "source": [
    "print(answer['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ea4d11-c744-4949-b55f-5c2eab79ac9e",
   "metadata": {},
   "source": [
    "#### Automating in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "571e850b-daf5-4ad8-84bf-cb33af51b321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You are a course teaching assistant.\n",
      "\n",
      "You are given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number\n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\" : \"SEARCH\",\n",
      "\"reasoning\" : \"<add your reasoning here>\",\n",
      "\"keywords\" : [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\" : \"ANSWER_CONTEXT\",\n",
      "\"answer\" : \"<your answer>\",\n",
      "\"source\" :\"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\" : \"ANSWER\",\n",
      "\"answer\" : \"<your answer>\",\n",
      "\"source\" : \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be succesful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT>\n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"Since the student is asking about success strategies for Module 1, it's important to find information related to Module 1 goals, requirements, and recommended study methods to improve their chances of success.\",\n",
      "  \"keywords\": [\n",
      "    \"Module 1 success tips\",\n",
      "    \"Module 1 requirements\",\n",
      "    \"how to excel in Module 1\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You are a course teaching assistant.\n",
      "\n",
      "You are given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number\n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\" : \"SEARCH\",\n",
      "\"reasoning\" : \"<add your reasoning here>\",\n",
      "\"keywords\" : [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\" : \"ANSWER_CONTEXT\",\n",
      "\"answer\" : \"<your answer>\",\n",
      "\"source\" :\"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\" : \"ANSWER\",\n",
      "\"answer\" : \"<your answer>\",\n",
      "\"source\" : \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be succesful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "Module 1 requirements\n",
      "Module 1 success tips\n",
      "how to excel in Module 1\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT>\n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module “kafka” not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"Since the student is asking about success strategies for Module 1, it's important to find information related to Module 1 goals, requirements, and recommended study methods to improve their chances of success.\", \"keywords\": [\"Module 1 success tips\", \"Module 1 requirements\", \"how to excel in Module 1\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"There's a need to gather more information specifically about success strategies or study tips for Module 1, as my previous search did not yield relevant insights related to success in Module 1.\",\n",
      "  \"keywords\": [\n",
      "    \"Module 1 tips for success\",\n",
      "    \"how to succeed in Module 1\",\n",
      "    \"best practices for Module 1\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #2...\n",
      "You are a course teaching assistant.\n",
      "\n",
      "You are given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number\n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\" : \"SEARCH\",\n",
      "\"reasoning\" : \"<add your reasoning here>\",\n",
      "\"keywords\" : [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\" : \"ANSWER_CONTEXT\",\n",
      "\"answer\" : \"<your answer>\",\n",
      "\"source\" :\"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\" : \"ANSWER\",\n",
      "\"answer\" : \"<your answer>\",\n",
      "\"source\" : \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be succesful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "Module 1 requirements\n",
      "how to succeed in Module 1\n",
      "how to excel in Module 1\n",
      "Module 1 success tips\n",
      "Module 1 tips for success\n",
      "best practices for Module 1\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT>\n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module “kafka” not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker - cs to store all code in your default Linux distro to get the best out of file system performance (since Docker runs on WSL2 backend by default for Windows 10 Home / Windows 11 Home users).\n",
      "answer: More info in the Docker Docs on Best Practises\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"Since the student is asking about success strategies for Module 1, it's important to find information related to Module 1 goals, requirements, and recommended study methods to improve their chances of success.\", \"keywords\": [\"Module 1 success tips\", \"Module 1 requirements\", \"how to excel in Module 1\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"There's a need to gather more information specifically about success strategies or study tips for Module 1, as my previous search did not yield relevant insights related to success in Module 1.\", \"keywords\": [\"Module 1 tips for success\", \"how to succeed in Module 1\", \"best practices for Module 1\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"To be successful in Module 1, focus on understanding the fundamental concepts of Docker and Terraform, as these are crucial for your learning in this module. Regularly engage with the course materials, practice consistently through exercises and projects, and utilize resources like forums or study groups for discussing challenges. Make sure to follow the best practices recommended for Docker usage, such as optimizing file system performance when running Docker on Windows 10 Home or Windows 11 using WSL2. Lastly, keep an eye on your code and environment setups to avoid common pitfalls related to missing modules or configuration issues.\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"what do I need to do to be succesful at module 1?\"\n",
    "\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "while True:\n",
    "    print(f'ITERATION #{iteration}...')\n",
    "\n",
    "    context = build_context(search_results)\n",
    "    prompt = prompt_template.format(\n",
    "        question = question,\n",
    "        context = context,\n",
    "        search_queries = \"\\n\".join(search_queries),\n",
    "        previous_actions = \"\\n\".join([json.dumps(a) for a in previous_actions]),\n",
    "        max_iterations = 3,\n",
    "        iteration_number = iteration\n",
    "    )\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(json.dumps(answer, indent=2))\n",
    "\n",
    "    previous_actions.append(answer)\n",
    "\n",
    "    action = answer['action']\n",
    "    if action != 'SEARCH':\n",
    "        break\n",
    "\n",
    "    keywords = answer['keywords']\n",
    "    search_queries = list(set(search_queries) | set(keywords))\n",
    "\n",
    "    for k in keywords:\n",
    "        res = search(k)\n",
    "        search_results.extend(res)\n",
    "\n",
    "    search_results = dedub(search_results)\n",
    "\n",
    "    iteration = iteration + 1\n",
    "    if iteration >= 4:\n",
    "        break\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4d145cf5-3fc3-4297-98ad-e0d604963e45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To be successful in Module 1, which focuses on Docker and Terraform, here are some general tips:\\n\\n1. **Understand the Basics of Docker:** Familiarize yourself with fundamental concepts such as images, containers, and orchestration. Make sure you are comfortable with Docker commands and workflows.\\n\\n2. **Learn Terraform Fundamentals:** Ensure you grasp Terraform's configuration language and how it manages infrastructure as code. Practice writing Terraform configurations and understand how to apply them.\\n\\n3. **Hands-On Practice:** Engage in as much hands-on practice as possible. Create your own Docker containers and configurations with Terraform for different scenarios to solidify your understanding.\\n\\n4. **Debugging Skills:** Develop debugging skills for both Docker and Terraform. Learn how to troubleshoot common issues that arise when building containers or managing infrastructure.\\n\\n5. **Follow Best Practices:** Refer to the Docker and Terraform documentation for best practices in deployment and management. This will help you avoid common pitfalls.\\n\\n6. **Engage with the Community:** Participate in forums or study groups related to Docker and Terraform. Discussing problems and solutions with peers can provide valuable insights and improve your learning experience.\\n\\n7. **Stay Organized:** Keep your projects organized, maintain clear documentation for your work, and manage your environment efficiently.\\n\\nBy following these guidelines, you can enhance your learning experience and increase your chances of success in Module 1.\",\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "80a1bf41-4585-42e3-9490-e9611fb077b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1893bd9c-67ec-446e-8c60-acbc47b301d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_search(question):\n",
    "    search_queries = []\n",
    "    search_results = []\n",
    "    previous_actions = []\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        print(f'ITERATION #{iteration}...')\n",
    "    \n",
    "        context = build_context(search_results)\n",
    "        prompt = prompt_template.format(\n",
    "            question = question,\n",
    "            context = context,\n",
    "            search_queries = \"\\n\".join(search_queries),\n",
    "            previous_actions = \"\\n\".join([json.dumps(a) for a in previous_actions]),\n",
    "            max_iterations = 3,\n",
    "            iteration_number = iteration\n",
    "        )\n",
    "    \n",
    "        print(prompt)\n",
    "    \n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(json.dumps(answer, indent=2))\n",
    "    \n",
    "        previous_actions.append(answer)\n",
    "    \n",
    "        action = answer['action']\n",
    "        if action != 'SEARCH':\n",
    "            break\n",
    "    \n",
    "        keywords = answer['keywords']\n",
    "        search_queries = list(set(search_queries) | set(keywords))\n",
    "    \n",
    "        for k in keywords:\n",
    "            res = search(k)\n",
    "            search_results.extend(res)\n",
    "    \n",
    "        search_results = dedub(search_results)\n",
    "    \n",
    "        iteration = iteration + 1\n",
    "        if iteration >= 4:\n",
    "            break\n",
    "        print()\n",
    "        \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ed378ea2-a4d2-4b5e-8aa0-d8395c10df35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You are a course teaching assistant.\n",
      "\n",
      "You are given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number\n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\" : \"SEARCH\",\n",
      "\"reasoning\" : \"<add your reasoning here>\",\n",
      "\"keywords\" : [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\" : \"ANSWER_CONTEXT\",\n",
      "\"answer\" : \"<your answer>\",\n",
      "\"source\" :\"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\" : \"ANSWER\",\n",
      "\"answer\" : \"<your answer>\",\n",
      "\"source\" : \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT>\n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"I need to gather specific advice or guidelines on course preparation from the FAQ database to provide the student with the most relevant and accurate information.\",\n",
      "  \"keywords\": [\n",
      "    \"course preparation\",\n",
      "    \"how to prepare for the course\",\n",
      "    \"student preparation tips\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You are a course teaching assistant.\n",
      "\n",
      "You are given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number\n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\" : \"SEARCH\",\n",
      "\"reasoning\" : \"<add your reasoning here>\",\n",
      "\"keywords\" : [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\" : \"ANSWER_CONTEXT\",\n",
      "\"answer\" : \"<your answer>\",\n",
      "\"source\" :\"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\" : \"ANSWER\",\n",
      "\"answer\" : \"<your answer>\",\n",
      "\"source\" : \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "course preparation\n",
      "how to prepare for the course\n",
      "student preparation tips\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT>\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Hadoop - Exception in thread \"main\" java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\n",
      "answer: If you are seeing this (or similar) error when attempting to write to parquet, it is likely an issue with your path variables.\n",
      "For Windows, create a new User Variable “HADOOP_HOME” that points to your Hadoop directory. Then add “%HADOOP_HOME%\\bin” to the PATH variable.\n",
      "Additional tips can be found here: https://stackoverflow.com/questions/41851066/exception-in-thread-main-java-lang-unsatisfiedlinkerror-org-apache-hadoop-io\n",
      "\n",
      "section: Module 3: Data Warehousing\n",
      "question: GCS Bucket - I query my dataset and get a Bad character (ASCII 0) error?\n",
      "answer: Check the Schema\n",
      "You might have a wrong formatting\n",
      "Try to upload the CSV.GZ files without formatting or going through pandas via wget\n",
      "See this Slack conversation for helpful tips\n",
      "\n",
      "section: Module 2: Workflow Orchestration\n",
      "question: Docker - 2.2.2 Configure Mage\n",
      "answer: Issue : Docker containers exit instantly with code 132, upon docker compose up\n",
      "Mage documentation has it listing the cause as \"older architecture\" .\n",
      "This might be a hardware issue, so unless you have another computer, you can't solve it without purchasing a new one, so the next best solution is a VM.\n",
      "This is from a student running on a VirtualBox VM, Ubuntu 22.04.3 LTS, Docker version 25.0.2. So not having the context on how the vbox was spin up with (CPU, RAM, network, etc), it’s really inconclusive at this time.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: GCP - The project to be billed is associated with an absent billing account\n",
      "answer: If you receive the error: “Error 403: The project to be billed is associated with an absent billing account., accountDisabled” It is most likely because you did not enter YOUR project ID. The snip below is from video 1.3.2\n",
      "The value you enter here will be unique to each student. You can find this value on your GCP Dashboard when you login.\n",
      "Ashish Agrawal\n",
      "Another possibility is that you have not linked your billing account to your current project\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"I need to gather specific advice or guidelines on course preparation from the FAQ database to provide the student with the most relevant and accurate information.\", \"keywords\": [\"course preparation\", \"how to prepare for the course\", \"student preparation tips\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"Since the previous search did not yield any specific preparation tips or guidelines for the course, I will perform a new search to find additional advice on how to prepare for the course effectively.\",\n",
      "  \"keywords\": [\n",
      "    \"getting started with the course\",\n",
      "    \"tips for new students\",\n",
      "    \"course readiness advice\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #2...\n",
      "You are a course teaching assistant.\n",
      "\n",
      "You are given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number\n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\" : \"SEARCH\",\n",
      "\"reasoning\" : \"<add your reasoning here>\",\n",
      "\"keywords\" : [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\" : \"ANSWER_CONTEXT\",\n",
      "\"answer\" : \"<your answer>\",\n",
      "\"source\" :\"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\" : \"ANSWER\",\n",
      "\"answer\" : \"<your answer>\",\n",
      "\"source\" : \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "how do I prepare for the course?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "course preparation\n",
      "getting started with the course\n",
      "student preparation tips\n",
      "tips for new students\n",
      "how to prepare for the course\n",
      "course readiness advice\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT>\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Hadoop - Exception in thread \"main\" java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\n",
      "answer: If you are seeing this (or similar) error when attempting to write to parquet, it is likely an issue with your path variables.\n",
      "For Windows, create a new User Variable “HADOOP_HOME” that points to your Hadoop directory. Then add “%HADOOP_HOME%\\bin” to the PATH variable.\n",
      "Additional tips can be found here: https://stackoverflow.com/questions/41851066/exception-in-thread-main-java-lang-unsatisfiedlinkerror-org-apache-hadoop-io\n",
      "\n",
      "section: Module 3: Data Warehousing\n",
      "question: GCS Bucket - I query my dataset and get a Bad character (ASCII 0) error?\n",
      "answer: Check the Schema\n",
      "You might have a wrong formatting\n",
      "Try to upload the CSV.GZ files without formatting or going through pandas via wget\n",
      "See this Slack conversation for helpful tips\n",
      "\n",
      "section: Module 2: Workflow Orchestration\n",
      "question: Docker - 2.2.2 Configure Mage\n",
      "answer: Issue : Docker containers exit instantly with code 132, upon docker compose up\n",
      "Mage documentation has it listing the cause as \"older architecture\" .\n",
      "This might be a hardware issue, so unless you have another computer, you can't solve it without purchasing a new one, so the next best solution is a VM.\n",
      "This is from a student running on a VirtualBox VM, Ubuntu 22.04.3 LTS, Docker version 25.0.2. So not having the context on how the vbox was spin up with (CPU, RAM, network, etc), it’s really inconclusive at this time.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: GCP - The project to be billed is associated with an absent billing account\n",
      "answer: If you receive the error: “Error 403: The project to be billed is associated with an absent billing account., accountDisabled” It is most likely because you did not enter YOUR project ID. The snip below is from video 1.3.2\n",
      "The value you enter here will be unique to each student. You can find this value on your GCP Dashboard when you login.\n",
      "Ashish Agrawal\n",
      "Another possibility is that you have not linked your billing account to your current project\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: dbt job - Triggered by pull requests is disabled when I try to create a new Continuous Integration job in dbt cloud.\n",
      "answer: Solution:\n",
      "Check if you’re on the Developer Plan. As per the prerequisites, you'll need to be enrolled in the Team Plan or Enterprise Plan to set up a CI Job in dbt Cloud.\n",
      "So If you're on the Developer Plan, you'll need to upgrade to utilise CI Jobs.\n",
      "Note from another user: I’m in the Team Plan (trial period) but the option is still disabled. What worked for me instead was this. It works for the Developer (free) plan.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How to troubleshoot issues\n",
      "answer: The first step is to try to solve the issue on your own. Get used to solving problems and reading documentation. This will be a real life skill you need when employed. [ctrl+f] is your friend, use it! It is a universal shortcut and works in all apps/browsers.\n",
      "What does the error say? There will often be a description of the error or instructions on what is needed or even how to fix it. I have even seen a link to the solution. Does it reference a specific line of your code?\n",
      "Restart app or server/pc.\n",
      "Google it, use ChatGPT, Bing AI etc.\n",
      "It is going to be rare that you are the first to have the problem, someone out there has posted the fly issue and likely the solution.\n",
      "Search using: <technology> <problem statement>. Example: pgcli error column c.relhasoids does not exist.\n",
      "There are often different solutions for the same problem due to variation in environments.\n",
      "Check the tech’s documentation. Use its search if available or use the browsers search function.\n",
      "Try uninstall (this may remove the bad actor) and reinstall of application or reimplementation of action. Remember to restart the server/pc for reinstalls.\n",
      "Sometimes reinstalling fails to resolve the issue but works if you uninstall first.\n",
      "Post your question to Stackoverflow. Read the Stackoverflow guide on posting good questions.\n",
      "https://stackoverflow.com/help/how-to-ask\n",
      "This will be your real life. Ask an expert in the future (in addition to coworkers).\n",
      "Ask in Slack\n",
      "Before asking a question,\n",
      "Check Pins (where the shortcut to the repo and this FAQ is located)\n",
      "Use the slack app’s search function\n",
      "Use the bot @ZoomcampQABot to do the search for you\n",
      "check the FAQ (this document), use search [ctrl+f]\n",
      "When asking a question, include as much information as possible:\n",
      "What are you coding on? What OS?\n",
      "What command did you run, which video did you follow? Etc etc\n",
      "What error did you get? Does it have a line number to the “offending” code and have you check it for typos?\n",
      "What have you tried that did not work? This answer is crucial as without it, helpers would ask you to do the suggestions in the error log first. Or just read this FAQ document.\n",
      "DO NOT use screenshots, especially don’t take pictures from a phone.\n",
      "DO NOT tag instructors, it may discourage others from helping you. Copy and paste errors; if it’s long, just post it in a reply to your thread.\n",
      "Use ``` for formatting your code.\n",
      "Use the same thread for the conversation (that means reply to your own thread).\n",
      "DO NOT create multiple posts to discuss the issue.\n",
      "learYou may create a new post if the issue reemerges down the road. Describe what has changed in the environment.\n",
      "Provide additional information in the same thread of the steps you have taken for resolution.\n",
      "Take a break and come back later. You will be amazed at how often you figure out the solution after letting your brain rest. Get some fresh air, workout, play a video game, watch a tv show, whatever allows your brain to not think about it for a little while or even until the next day.\n",
      "Remember technology issues in real life sometimes take days or even weeks to resolve.\n",
      "If somebody helped you with your problem and it's not in the FAQ, please add it there. It will help other students.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Environment - Is the course [Windows/mac/Linux/...] friendly?\n",
      "answer: Yes! Linux is ideal but technically it should not matter. Students last year used all 3 OSes successfully\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"I need to gather specific advice or guidelines on course preparation from the FAQ database to provide the student with the most relevant and accurate information.\", \"keywords\": [\"course preparation\", \"how to prepare for the course\", \"student preparation tips\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"Since the previous search did not yield any specific preparation tips or guidelines for the course, I will perform a new search to find additional advice on how to prepare for the course effectively.\", \"keywords\": [\"getting started with the course\", \"tips for new students\", \"course readiness advice\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"To prepare for the course, ensure you register before the start date (January 15, 2024), and join the course's public Google Calendar and Telegram channel for announcements. Familiarize yourself with the course materials available via DataTalks.Club\\u2019s Slack and make sure to have your tools set up as outlined in the course guidelines. It's recommended to have a good path setup for any necessary tools like GitHub. Overall, being organized and proactive in setting up your environment will greatly enhance your experience in the course.\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To prepare for the course, ensure you register before the start date (January 15, 2024), and join the course's public Google Calendar and Telegram channel for announcements. Familiarize yourself with the course materials available via DataTalks.Club’s Slack and make sure to have your tools set up as outlined in the course guidelines. It's recommended to have a good path setup for any necessary tools like GitHub. Overall, being organized and proactive in setting up your environment will greatly enhance your experience in the course.\",\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_search(\"how do I prepare for the course?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d0c7c43f-333d-4f47-bde4-f4dd6340e406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To prepare for the course, ensure you register before the start date (January 15, 2024), and join the course's public Google Calendar and Telegram channel for announcements. Familiarize yourself with the course materials available via DataTalks.Club’s Slack and make sure to have your tools set up as outlined in the course guidelines. It's recommended to have a good path setup for any necessary tools like GitHub. Overall, being organized and proactive in setting up your environment will greatly enhance your experience in the course.\n"
     ]
    }
   ],
   "source": [
    "print(_['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66ff8de-57b9-4c6b-999f-4e7330f47a9e",
   "metadata": {},
   "source": [
    "#### Function calling (\"tool use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "872f005f-75b5-4697-b2db-e9c0553d90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aafca73-9e92-4309-a94e-5c21ccf5abca",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = {\n",
    "    \"type\" : \"function\",\n",
    "    \"name\" : \"search\",\n",
    "    \"description\" : \"Search the FAQ database\",\n",
    "    \"parameters\" : {\n",
    "        \"type\" : \"object\",\n",
    "        \"properties\" : {\n",
    "            \"query\" : {\n",
    "                \"type\" : \"string\",\n",
    "                \"description\" : \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\" : [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e957dd0-7207-4d55-a3a7-41b128877eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\"query\":\"how to do well in module 1\"}', call_id='call_NTq1lONeQXpTiAY7QnsLzsmb', name='search', type='function_call', id='fc_68a427c520c08197bd6cce773d7373e40452ecbb4a428749', status='completed')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"how do I do well in module 1?\"\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\"\"\".strip()\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\" : \"developer\", \"content\" : developer_prompt},\n",
    "    {\"role\" : \"user\", \"content\" : question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = 'gpt-4o-mini',\n",
    "    input = chat_messages,\n",
    "    tools = tools\n",
    ")\n",
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c47f3535-5751-40f4-8200-370e2a20c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calls = response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c034929b-2514-4eec-89bb-b1b3a012da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "call = calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d9914ab-84e8-4fac-8c3a-0d01873b68d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = call.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e66f0a6-e6c6-4b38-bc72-4cd6669e528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = json.loads(call.arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30e17b9-1cd5-44f6-915f-b3929cb92100",
   "metadata": {},
   "source": [
    "#### globabls - Note\n",
    "globals() returns a dictionary that represents the current global symbol table.\n",
    "This dictionary contains all global names (variables, functions, classes, imports, etc.) that are defined in the current module.\n",
    "- globals(): Fast & flexible, but risky and too open.\n",
    "- getattr(tools, \"hello\") is similar to globals()[\"hello\"], but scoped to the tools module instead of everything in your global namespace. If all the functions live inside a specific module (say tools.py).\n",
    "- production systems usually use a dispatcher dictionary: FastAPI doesn’t use globals() or getattr directly. Instead, it uses a registry of routes (functions) attached to an APIRouter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2926d571-17c1-47c5-8b0f-e5d109bd3b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.search(query)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[f_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9df8daa9-d41f-462a-8855-33c2a2465127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.search(query)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gives a pointer to the search functions same as above\n",
    "globals()['search']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e966964-18b7-47bd-b0ec-0619043e8b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = globals()[f_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a2ba89e-99a2-423f-9da6-dac748f42826",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#it passes all the arguments to the function search or f here\n",
    "search_results = f(**arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66c733cd-8e1b-44dd-8e73-03bf6ef33729",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages.append(call)\n",
    "\n",
    "chat_messages.append({\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": call.call_id,\n",
    "    \"output\": json.dumps(search_results),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fadefbc-74d9-4040-85a5-faa00c11f645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'developer',\n",
       "  'content': \"You're a course teaching assistant.\\nYou're given a question from a course student and your task is to answer it.\"},\n",
       " {'role': 'user', 'content': 'how do I do well in module 1?'},\n",
       " ResponseFunctionToolCall(arguments='{\"query\":\"how to do well in module 1\"}', call_id='call_NTq1lONeQXpTiAY7QnsLzsmb', name='search', type='function_call', id='fc_68a427c520c08197bd6cce773d7373e40452ecbb4a428749', status='completed'),\n",
       " {'type': 'function_call_output',\n",
       "  'call_id': 'call_NTq1lONeQXpTiAY7QnsLzsmb',\n",
       "  'output': '[{\"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\\\nThe solution which worked for me(use following in jupyter notebook) :\\\\n!pip install findspark\\\\nimport findspark\\\\nfindspark.init()\\\\nThereafter , import pyspark and create spark contex<<t as usual\\\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\\\nFilter based on conditions based on multiple columns\\\\nfrom pyspark.sql.functions import col\\\\nnew_final.filter((new_final.a_zone==\\\\\"Murray Hill\\\\\") & (new_final.b_zone==\\\\\"Midwood\\\\\")).show()\\\\nKrishna Anand\", \"section\": \"Module 5: pyspark\", \"question\": \"Module Not Found Error in Jupyter Notebook .\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 322}, {\"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\\\nexport PYTHONPATH=\\\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\\\u201d\\\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\\\"` appropriately.\\\\nAdditionally, you can check for the version of \\\\u2018py4j\\\\u2019 of the spark you\\\\u2019re using from here and update as mentioned above.\\\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\", \"section\": \"Module 5: pyspark\", \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 323}, {\"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named \\'pytz\\'`\\\\nSolution:\\\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", \"section\": \"Module 4: analytics engineering with dbt\", \"question\": \"DBT - Error: No module named \\'pytz\\' while setting up dbt with docker\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 299}, {\"text\": \"create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\')  I get the error \\\\\"TypeError: \\'module\\' object is not callable\\\\\"\\\\nSolution:\\\\nconn_string = \\\\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\\\"\\\\nengine = create_engine(conn_string)\", \"section\": \"Module 1: Docker and Terraform\", \"question\": \"Python - SQLALchemy - TypeError \\'module\\' object is not callable\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 124}, {\"text\": \"Error raised during the jupyter notebook\\\\u2019s cell execution:\\\\nengine = create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\').\\\\nSolution: Need to install Python module \\\\u201cpsycopg2\\\\u201d. Can be installed by Conda or pip.\", \"section\": \"Module 1: Docker and Terraform\", \"question\": \"Python - SQLAlchemy - ModuleNotFoundError: No module named \\'psycopg2\\'.\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 125}]'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0de6a68e-5c07-44a6-ad0c-a7832b486e34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseOutputMessage(id='msg_68a427cb4e008197a76d10fea6cc85290452ecbb4a428749', content=[ResponseOutputText(annotations=[], text=\"To do well in Module 1, here are some tips that can help you:\\n\\n1. **Understand the Content**: Make sure you grasp the foundational concepts around Docker and Terraform, as these are essential for the module.\\n\\n2. **Practice Hands-On**: Set up Docker and Terraform in your local environment. Hands-on practice solidifies theoretical knowledge.\\n\\n3. **Follow the Documentation**: Refer to any available documentation or course materials closely. They often contain valuable insights and instructions.\\n\\n4. **Engage with Fellow Students**: Join discussions with peers or form study groups. This can help clarify doubts and share different perspectives.\\n\\n5. **Utilize Resources**: Don’t hesitate to seek additional resources like tutorials, videos, or forums relevant to Docker and Terraform.\\n\\n6. **Labs and Assignments**: Complete all labs and assignments promptly. These are designed to reinforce your learning.\\n\\n7. **Seek Help When Needed**: If you're facing errors (like those concerning `psycopg2` or SQLAlchemy), refer to the course FAQs or ask for help in forums.\\n\\n8. **Review and Revise**: Regularly review the concepts you've learned to reinforce your understanding and retention.\\n\\nBy following these strategies and utilizing the available resources effectively, you should be well-prepared to excel in Module 1.\", type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#invoke the call one more time\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = 'gpt-4o-mini',\n",
    "    input = chat_messages,\n",
    "    tools = tools\n",
    ")\n",
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d2ab484-b7ed-4ccc-9d40-1f8dbc45cbe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To do well in Module 1, here are some tips that can help you:\n",
      "\n",
      "1. **Understand the Content**: Make sure you grasp the foundational concepts around Docker and Terraform, as these are essential for the module.\n",
      "\n",
      "2. **Practice Hands-On**: Set up Docker and Terraform in your local environment. Hands-on practice solidifies theoretical knowledge.\n",
      "\n",
      "3. **Follow the Documentation**: Refer to any available documentation or course materials closely. They often contain valuable insights and instructions.\n",
      "\n",
      "4. **Engage with Fellow Students**: Join discussions with peers or form study groups. This can help clarify doubts and share different perspectives.\n",
      "\n",
      "5. **Utilize Resources**: Don’t hesitate to seek additional resources like tutorials, videos, or forums relevant to Docker and Terraform.\n",
      "\n",
      "6. **Labs and Assignments**: Complete all labs and assignments promptly. These are designed to reinforce your learning.\n",
      "\n",
      "7. **Seek Help When Needed**: If you're facing errors (like those concerning `psycopg2` or SQLAlchemy), refer to the course FAQs or ask for help in forums.\n",
      "\n",
      "8. **Review and Revise**: Regularly review the concepts you've learned to reinforce your understanding and retention.\n",
      "\n",
      "By following these strategies and utilizing the available resources effectively, you should be well-prepared to excel in Module 1.\n"
     ]
    }
   ],
   "source": [
    "print(response.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f266f5a-427d-4348-9403-a8fa015d18e4",
   "metadata": {},
   "source": [
    "#### Multiple calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92a19cd2-6e4b-4e30-8707-0fdbee3ccac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\"query\":\"do well in module 1\"}', call_id='call_ditbBMCVdlHoqpMWayDn74rP', name='search', type='function_call', id='fc_68a427d2079881979fc7a79c7ac002f2040497bb7dd486be', status='completed'),\n",
       " ResponseFunctionToolCall(arguments='{\"query\":\"module 1 tips for success\"}', call_id='call_f8eh23U3FzImHcJ2qjtGmwqu', name='search', type='function_call', id='fc_68a427d26824819789829c7c66a00c3a040497bb7dd486be', status='completed'),\n",
       " ResponseFunctionToolCall(arguments='{\"query\":\"how to excel in module 1\"}', call_id='call_OBOTY3zOOgL3kKcxS8xjiOPO', name='search', type='function_call', id='fc_68a427d2d55c819787a14d3620f77cab040497bb7dd486be', status='completed')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"how do I do well in module 1?\"\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "You're given a question from a course student and your task is to answer it.\n",
    "If you look up something in FAQ, convert the student question into multiple queries.\n",
    "\"\"\".strip()\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\" : \"developer\", \"content\" : developer_prompt},\n",
    "    {\"role\" : \"user\", \"content\" : question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = 'gpt-4o-mini',\n",
    "    input = chat_messages,\n",
    "    tools = tools\n",
    ")\n",
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a583faaa-8489-41ed-90ed-4bc9c18bf645",
   "metadata": {},
   "outputs": [],
   "source": [
    "calls = response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "139c669d-90fd-46a6-8a2d-9a41cbda484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for call in calls:\n",
    "    f_name = call.name\n",
    "    arguments = json.loads(call.arguments)\n",
    "    f = globals()[f_name]\n",
    "    results = f(**arguments)\n",
    "    chat_messages.append(call)\n",
    "    \n",
    "    chat_messages.append({\n",
    "        \"type\" : \"function_call_output\",\n",
    "        \"call_id\" : call.call_id,\n",
    "        \"output\" : json.dumps(results),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d2f06ba-64a1-4fb7-8c02-d38cff8eed0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseOutputMessage(id='msg_68a427d797a88197b31aee4f923a7563040497bb7dd486be', content=[ResponseOutputText(annotations=[], text='To excel in Module 1, here are several key tips and resources:\\n\\n1. **Understanding Core Technologies**: Ensure you are comfortable with the foundational technologies explored in the module, such as Docker and Terraform. Familiarizing yourself with these tools will aid in your execution of assignments.\\n\\n2. **Practice Hands-On**: Engage in practical exercises provided in the module. Try to replicate the examples and experiment with variations based on your understanding. This will solidify your knowledge.\\n\\n3. **Troubleshooting**: If you encounter issues such as `ModuleNotFoundError`, ensure all necessary packages are installed correctly. For example:\\n   - If facing issues with `psycopg2`, ensure you\\'ve run:\\n     ```bash\\n     pip install psycopg2-binary\\n     ```\\n   - For SQLAlchemy errors, verify your connection string is correct:\\n     ```python\\n     conn_string = \"postgresql+psycopg://username:password@localhost:5432/db_name\"\\n     ```\\n\\n4. **Use Provided Resources**: Don\\'t hesitate to revisit the course materials or additional documentation recommended in the module. There might be helpful tips that can clarify complex topics.\\n\\n5. **Engagement**: Participate in discussion forums or study groups with fellow students. Sharing knowledge and experiences can enhance your understanding.\\n\\n6. **Seek Help When Needed**: If you\\'re stuck, reach out for assistance—whether it’s from instructors, peers, or online communities.\\n\\nBy incorporating these strategies, you’ll be well on your way to doing well in Module 1!', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model = 'gpt-4o-mini',\n",
    "    input = chat_messages,\n",
    "    tools = tools\n",
    ")\n",
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abdf677b-bfe0-420c-882c-aeddb1446a1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To excel in Module 1, here are several key tips and resources:\n",
      "\n",
      "1. **Understanding Core Technologies**: Ensure you are comfortable with the foundational technologies explored in the module, such as Docker and Terraform. Familiarizing yourself with these tools will aid in your execution of assignments.\n",
      "\n",
      "2. **Practice Hands-On**: Engage in practical exercises provided in the module. Try to replicate the examples and experiment with variations based on your understanding. This will solidify your knowledge.\n",
      "\n",
      "3. **Troubleshooting**: If you encounter issues such as `ModuleNotFoundError`, ensure all necessary packages are installed correctly. For example:\n",
      "   - If facing issues with `psycopg2`, ensure you've run:\n",
      "     ```bash\n",
      "     pip install psycopg2-binary\n",
      "     ```\n",
      "   - For SQLAlchemy errors, verify your connection string is correct:\n",
      "     ```python\n",
      "     conn_string = \"postgresql+psycopg://username:password@localhost:5432/db_name\"\n",
      "     ```\n",
      "\n",
      "4. **Use Provided Resources**: Don't hesitate to revisit the course materials or additional documentation recommended in the module. There might be helpful tips that can clarify complex topics.\n",
      "\n",
      "5. **Engagement**: Participate in discussion forums or study groups with fellow students. Sharing knowledge and experiences can enhance your understanding.\n",
      "\n",
      "6. **Seek Help When Needed**: If you're stuck, reach out for assistance—whether it’s from instructors, peers, or online communities.\n",
      "\n",
      "By incorporating these strategies, you’ll be well on your way to doing well in Module 1!\n"
     ]
    }
   ],
   "source": [
    "print(response.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d46f58-7e33-438d-bf41-28e24ccb923a",
   "metadata": {},
   "source": [
    "#### refactor and make it like a chat interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bac490d6-a950-4287-9c51-e5208cf67aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77b3b7b4-5693-49ca-a119-8703c1bb5363",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = {\n",
    "    \"type\" : \"function\",\n",
    "    \"name\" : \"search\",\n",
    "    \"description\" : \"Search the FAQ database\",\n",
    "    \"parameters\" : {\n",
    "        \"type\" : \"object\",\n",
    "        \"properties\" : {\n",
    "            \"query\" : {\n",
    "                \"type\" : \"string\",\n",
    "                \"description\" : \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\" : [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "110ebf9e-1b88-4682-99ee-514e50009bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_call(tool_call_response):\n",
    "    function_name = tool_call_response.name\n",
    "    arguments = json.loads(tool_call_response.arguments)\n",
    "\n",
    "    f = globals()[function_name]\n",
    "    result = f(**arguments)\n",
    "\n",
    "    return {\n",
    "        \"type\" : \"function_call_output\",\n",
    "        \"call_id\" :tool_call_response.call_id,\n",
    "        \"output\" : json.dumps(result, indent=2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "470ce66f-2902-431d-aaff-7778478e2c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\"query\":\"how to do well in module 1\"}', call_id='call_o44gqRJ16NwuOqgEHZft8cgB', name='search', type='function_call', id='fc_68a429a9a5c08194ab642276ca29ecc50a874687391c6768', status='completed'),\n",
       " ResponseFunctionToolCall(arguments='{\"query\":\"tips for success in module 1\"}', call_id='call_bWvunwnrR8itpoKkG1FTuZzb', name='search', type='function_call', id='fc_68a429a9f6388194a17be362d6171cf30a874687391c6768', status='completed')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"how do I do well in module 1?\"\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "You're given a question from a course student and your task is to answer it.\n",
    "If you look up something in FAQ, convert the student question into multiple queries.\n",
    "\"\"\".strip()\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\" : \"developer\", \"content\" : developer_prompt},\n",
    "    {\"role\" : \"user\", \"content\" : question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = 'gpt-4o-mini',\n",
    "    input = chat_messages,\n",
    "    tools = tools\n",
    ")\n",
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48d438f9-a90d-46ba-9e2e-16cf0c803b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for call in calls:\n",
    "    result = do_call(call)\n",
    "    chat_messages.append(call)\n",
    "    chat_messages.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2018b5df-85c6-4b6e-96c7-816b7c77ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model = 'gpt-4o-mini',\n",
    "    input = chat_messages,\n",
    "    tools = tools\n",
    ")\n",
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1712f-98b1-41d4-a6c8-00236f561824",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in response.output:\n",
    "    chat_messages.append(entry)\n",
    "    print(entry.type)\n",
    "\n",
    "    if entry.type == 'function_call':\n",
    "        result = do_call(entry)\n",
    "        chat_messages.append(result)\n",
    "    elif entry.typ == 'message':\n",
    "        print(entry.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08ca5a4-099d-48e2-ae2b-4664f73913f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
